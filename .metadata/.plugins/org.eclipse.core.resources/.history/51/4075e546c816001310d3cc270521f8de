import json
import numpy as np
import pandas as pd
from sklearn.naive_bayes import BernoulliNB
from sklearn.feature_extraction.text import CountVectorizer

# Set a seed for consistant results
###############################################################################
# Load Data into pandas and Preprocess Features
###############################################################################
X = pd.read_csv('data/train.tsv', sep="\t", na_values=['?'], index_col=1)
X_test = pd.read_csv('data/test.tsv', sep="\t", na_values=['?'], index_col=1)
y = X['label']
X = X.drop(['label'], axis=1)
# Combine test and train while we do our preprocessing
X_all = pd.concat([X_test, X])

X_all['boilerplate'] = X_all['boilerplate'].apply(json.loads)
# Initialize the data as a unicode string
X_all['body'] = u'empty'
# Run through the dataframe row-by-row, building the new columns with info
# extracted from the boilerplate
# NOTE: Works fine on this small dataset, but probably not the most efficient
# way to do this, if you have any tips please let me know.
for row in X_all.index:
    # First check that the body exists
    if 'body' in X_all['boilerplate'][row].keys():
	# If the field exists but the value is missing, replace with a custom
	# "empty" flag.  Otherwise the CountVectorizer below will breaks.
	if pd.isnull(X_all['boilerplate'][row]['body']):
	    # the other values in 'body' are unicode strings 
	    X_all['body'][row] = u'empty'
	else:
            X_all['body'][row] = X_all['boilerplate'][row]['body']
print "%s | %s" % (y[0],X_all['body'][0])

def construct_line( label, line ):
	new_line = []
	if float( label ) == 0.0:
		label = "-1"
	new_line.append( "%s " % ( label ))
	
	namespaces = [ 'e0', 'e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'e7' ]
	
	#for i, item in enumerate( line ):
	for n in namespaces:
		item = line.pop( 0 )
		new_item = "|%s %s" % ( n, item )
		new_line.append( new_item )
	new_line = " ".join( new_line )
	new_line += "\n"
	return new_line

